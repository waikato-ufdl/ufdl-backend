{
  "name": "mmclass_0.25.0_mobilenetv3_small_image_class_train",
  "version": 1,
  "description": "Training image classification models using MobileNetV3-Small via MMClassification",
  "scope": "public",
  "domain": "ic",
  "licence": "Apache 2.0",
  "specific": {
    "job_type": "Train<Domain<'Image Classification'>, Framework<'mobilenetv3-small', 'mmclass_0.25.0'>>",
    "executor_class": "ufdl.joblauncher.classify.mmclassification.ImageClassificationTrain_MMClass_0_25_0",
    "required_packages": "git+https://github.com/waikato-ufdl/ufdl-job-launcher-plugins.git",
    "parameters":
    {
      "dataset_options": {
        "types": ["Array<str>", "str"],
        "default": [
          "write-labels",
          "-f", "csv-headless",
          "-o", "labels.txt",
          "to-subdir-ic",
          "-o", ".",
          "--split-names", "train", "test", "val",
          "--split-ratios", "70", "15", "15"
        ],
        "help": "Options to pass to wai-annotations when downloading the dataset"
      },
      "docker_image": {
        "types": [
          "Name<DockerImage<Domain<'Image Classification'>, Framework<'mmclass', '0.25.0'>>>",
          "DockerImage<Domain<'Image Classification'>, Framework<'mmclass', '0.25.0'>>",
          "PK<DockerImage<Domain<'Image Classification'>, Framework<'mmclass', '0.25.0'>>>"
        ],
        "help": "The docker image to use"
      },
      "epochs": {
        "types": ["int"],
        "default": 20,
        "help": "The number of training steps to perform."
      },
      "checkpoint_interval": {
        "types": ["int"],
        "default": 20,
        "help": "How often to checkpoint the model."
      },
      "batch_size": {
        "types": ["int"],
        "default": 16,
        "help": "The number of images to in a batch (per GPU)."
      },
      "pretrained_model": {
        "types": [
          "Nothing",
          "Name<PretrainedModel<Domain<'Image Classification'>, Framework<'mobilenetv3-small', 'mmclass_0.25.0'>>>",
          "PK<PretrainedModel<Domain<'Image Classification'>, Framework<'mobilenetv3-small', 'mmclass_0.25.0'>>>",
          "PretrainedModel<Domain<'Image Classification'>, Framework<'mobilenetv3-small', 'mmclass_0.25.0'>>"
        ],
        "default": null,
        "help": "The pretrained model to fine-tune."
      },
      "body": {
        "types": ["Array<str>", "str"],
        "default": [
          "model = dict(",
          "    type='ImageClassifier',",
          "    backbone=dict(",
          "        type='MobileNetV3',",
          "        arch='small',",
          "        ${pretrained_model_config}",
          "    ),",
          "    neck=dict(type='GlobalAveragePooling'),",
          "    head=dict(",
          "        type='StackedLinearClsHead',",
          "        num_classes=${num-classes},",
          "        in_channels=576,",
          "        mid_channels=[1280],",
          "        act_cfg=dict(type='HSwish'),",
          "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),",
          "        topk=(1, 5)))",
          "img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)",
          "train_pipeline = [",
          "    dict(type='LoadImageFromFile'),",
          "    dict(type='RandomResizedCrop', size=224),",
          "    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),",
          "    dict(type='Normalize', **img_norm_cfg),",
          "    dict(type='ImageToTensor', keys=['img']),",
          "    dict(type='ToTensor', keys=['gt_label']),",
          "    dict(type='Collect', keys=['img', 'gt_label'])",
          "]",
          "test_pipeline = [",
          "    dict(type='LoadImageFromFile'),",
          "    dict(type='Resize', size=(256, -1)),",
          "    dict(type='CenterCrop', crop_size=224),",
          "    dict(type='Normalize', **img_norm_cfg),",
          "    dict(type='ImageToTensor', keys=['img']),",
          "    dict(type='Collect', keys=['img'])",
          "]",
          "data = dict(",
          "    samples_per_gpu=${batch_size},",
          "    workers_per_gpu=2,",
          "    train=dict(",
          "        type='ExternalDataset',",
          "        data_prefix='/workspace/data/train',",
          "        pipeline=train_pipeline),",
          "    val=dict(",
          "        type='ExternalDataset',",
          "        data_prefix='/workspace/data/val',",
          "        ann_file=None,",
          "        pipeline=test_pipeline),",
          "    test=dict(",
          "        type='ExternalDataset',",
          "        data_prefix='/workspace/data/test',",
          "        ann_file=None,",
          "        pipeline=test_pipeline))",
          "evaluation = dict(interval=1, metric='accuracy')",
          "optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)",
          "optimizer_config = dict(grad_clip=None)",
          "lr_config = dict(policy='step', step=[120, 170])",
          "runner = dict(type='EpochBasedRunner', max_epochs=${epochs})",
          "checkpoint_config = dict(interval=${checkpoint_interval})",
          "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])",
          "dist_params = dict(backend='nccl')",
          "log_level = 'INFO'",
          "load_from = None",
          "resume_from = None",
          "workflow = [('train', 1)]"
        ],
        "help": "The command passed to the Docker image."
      }
    }
  }
}
