{
  "name": "mmdetection_2020-03-01_retinanet_x101_32x4d_fpn_1x-train",
  "version": 1,
  "description": "Building RetinaNet X-101 FPN models using MMDetection 2020-03-01\nOriginal config file: https://github.com/open-mmlab/mmdetection/blob/b6b80a0b37aac46039acd62e01ec3ce93fb03900/configs/retinanet/retinanet_x101_32x4d_fpn_1x_coco.py",
  "scope": "public",
  "domain": "od",
  "licence": "Apache 2.0",
  "specific": {
    "job_type": "Train<Domain<'Object Detection'>, Framework<'mmdetection', '2020-03-01'>>",
    "executor_class": "ufdl.joblauncher.objdet.mmdetection.ObjectDetectionTrain_MMDet_20200301",
    "required_packages": "git+https://github.com/waikato-ufdl/ufdl-job-launcher-plugins.git",
    "parameters":
    {
      "dataset_options": {
        "types": ["Array<str>", "str"],
        "default": [
          "to-coco-od",
          "--sort-categories",
          "--category-output-file", "labels.txt",
          "-o", "annotations.json",
          "--split-names", "train", "test", "val",
          "--split-ratios", "70", "15", "15"
        ],
        "help": "Options for converting the input dataset"
      },
      "docker_image": {
        "types": [
          "DockerImage<Domain<'Object Detection'>, Framework<'mmdetection', '2020-03-01'>>",
          "PK<DockerImage<Domain<'Object Detection'>, Framework<'mmdetection', '2020-03-01'>>>",
          "Name<DockerImage<Domain<'Object Detection'>, Framework<'mmdetection', '2020-03-01'>>>"
        ],
        "help": "The docker image to use"
      },
      "epochs": {
        "types": ["int"],
        "default": 200,
        "help": "The number of training epochs to perform."
      },
      "checkpoint_interval": {
        "types": ["int"],
        "default": 50,
        "help": "The number of training epochs after which to save a checkpoint (at most the number of epochs)."
      },
      "image_width": {
        "types": ["int"],
        "default": 1333,
        "help": "The width to scale the images to."
      },
      "image_height": {
        "types": ["int"],
        "default": 800,
        "help": "The height to scale the images to."
      },
      "pretrained_model": {
        "types": ["str"],
        "default": "retinanet_x101_32x4d_fpn_1x_coco_20200130-5c8b7ec4",
        "help": "The pretrained ResNext101 model to use."
      },
      "shared_memory_size": {
        "types": ["str"],
        "default": "8G",
        "help": "The shared memory size to use for launching the docker container."
      },
      "body": {
        "types": ["Array<str>", "str"],
        "default": [
          "# model settings",
          "# Original config file: https://github.com/open-mmlab/mmdetection/blob/b6b80a0b37aac46039acd62e01ec3ce93fb03900/configs/retinanet/retinanet_x101_32x4d_fpn_1x_coco.py",
          "model = dict(",
          "    type='RetinaNet',",
          "    pretrained='open-mmlab://resnext101_32x4d',",
          "    backbone=dict(",
          "        type='ResNeXt',",
          "        depth=101,",
          "        groups=32,",
          "        base_width=4,",
          "        num_stages=4,",
          "        out_indices=(0, 1, 2, 3),",
          "        frozen_stages=1,",
          "        style='pytorch'),",
          "    neck=dict(",
          "        type='FPN',",
          "        in_channels=[256, 512, 1024, 2048],",
          "        out_channels=256,",
          "        start_level=1,",
          "        add_extra_convs=True,",
          "        num_outs=5),",
          "    bbox_head=dict(",
          "        type='RetinaHead',",
          "        num_classes=81,",
          "        in_channels=256,",
          "        stacked_convs=4,",
          "        feat_channels=256,",
          "        octave_base_scale=4,",
          "        scales_per_octave=3,",
          "        anchor_ratios=[0.5, 1.0, 2.0],",
          "        anchor_strides=[8, 16, 32, 64, 128],",
          "        target_means=[.0, .0, .0, .0],",
          "        target_stds=[1.0, 1.0, 1.0, 1.0],",
          "        loss_cls=dict(",
          "            type='FocalLoss',",
          "            use_sigmoid=True,",
          "            gamma=2.0,",
          "            alpha=0.25,",
          "            loss_weight=1.0),",
          "        loss_bbox=dict(type='SmoothL1Loss', beta=0.11, loss_weight=1.0)))",
          "# training and testing settings",
          "train_cfg = dict(",
          "    assigner=dict(",
          "        type='MaxIoUAssigner',",
          "        pos_iou_thr=0.5,",
          "        neg_iou_thr=0.4,",
          "        min_pos_iou=0,",
          "        ignore_iof_thr=-1),",
          "    allowed_border=-1,",
          "    pos_weight=-1,",
          "    debug=False)",
          "test_cfg = dict(",
          "    nms_pre=1000,",
          "    min_bbox_size=0,",
          "    score_thr=0.05,",
          "    nms=dict(type='nms', iou_thr=0.5),",
          "    max_per_img=100)",
          "# dataset settings",
          "dataset_type = 'CocoDataset'",
          "data_root = '/data'",
          "img_norm_cfg = dict(",
          "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)",
          "train_pipeline = [",
          "    dict(type='LoadImageFromFile'),",
          "    dict(type='LoadAnnotations', with_bbox=True),",
          "    dict(type='Resize', img_scale=(${image_width}, ${image_height}), keep_ratio=True),",
          "    dict(type='RandomFlip', flip_ratio=0.5),",
          "    dict(type='Normalize', **img_norm_cfg),",
          "    dict(type='Pad', size_divisor=32),",
          "    dict(type='DefaultFormatBundle'),",
          "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),",
          "]",
          "test_pipeline = [",
          "    dict(type='LoadImageFromFile'),",
          "    dict(",
          "        type='MultiScaleFlipAug',",
          "        img_scale=(${image_width}, ${image_height}),",
          "        flip=False,",
          "        transforms=[",
          "            dict(type='Resize', keep_ratio=True),",
          "            dict(type='RandomFlip'),",
          "            dict(type='Normalize', **img_norm_cfg),",
          "            dict(type='Pad', size_divisor=32),",
          "            dict(type='ImageToTensor', keys=['img']),",
          "            dict(type='Collect', keys=['img']),",
          "        ])",
          "]",
          "data = dict(",
          "    imgs_per_gpu=2,",
          "    workers_per_gpu=2,",
          "    train=dict(",
          "        type=dataset_type,",
          "        ann_file=data_root + '/train/annotations.json',",
          "        img_prefix=data_root + '/train/',",
          "        pipeline=train_pipeline),",
          "    val=dict(",
          "        type=dataset_type,",
          "        ann_file=data_root + '/val/annotations.json',",
          "        img_prefix=data_root + '/val/',",
          "        pipeline=test_pipeline),",
          "    test=dict(",
          "        type=dataset_type,",
          "        ann_file=data_root + '/test/annotations.json',",
          "        img_prefix=data_root + '/test/',",
          "        pipeline=test_pipeline))",
          "evaluation = dict(interval=1, metric='bbox')",
          "# optimizer",
          "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)",
          "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))",
          "# learning policy",
          "lr_config = dict(",
          "    policy='step',",
          "    warmup='linear',",
          "    warmup_iters=500,",
          "    warmup_ratio=1.0 / 3,",
          "    step=[8, 11])",
          "checkpoint_config = dict(interval=${checkpoint_interval})",
          "# yapf:disable",
          "log_config = dict(",
          "    interval=50,",
          "    hooks=[",
          "        dict(type='TextLoggerHook'),",
          "        # dict(type='TensorboardLoggerHook')",
          "    ])",
          "# yapf:enable",
          "# runtime settings",
          "total_epochs = ${epochs}",
          "dist_params = dict(backend='nccl')",
          "log_level = 'INFO'",
          "work_dir = '/output'",
          "load_from = '/data/pretrained_model.pth'",
          "resume_from = None",
          "workflow = [('train', 1)]",
          ""
        ],
        "help": "The body of the function"
      }
    }
  }
}
