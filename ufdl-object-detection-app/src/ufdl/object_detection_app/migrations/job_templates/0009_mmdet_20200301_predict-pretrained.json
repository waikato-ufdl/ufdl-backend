{
  "name": "mmdet_2020-03-01-predict-pretrained",
  "version": 1,
  "description": "Making predictions using pretrained object detection models built with MMDetection 2020-03-01",
  "scope": "public",
  "domain": "od",
  "framework": "mmdetection|2020-03-01",
  "licence": "Apache 2.0",
  "job_type": "predict",
  "executor_class": "ufdl.joblauncher.objdet.mmdetection.ObjectDetectionPredictPretrained_MMDet_20200301",
  "required_packages": "git+https://github.com/waikato-ufdl/ufdl-job-launcher-plugins.git",
  "inputs":
  [
    {
      "name": "data",
      "type": "dataset",
      "options": "to-coco",
      "help": "The dataset to generate predictions for."
    }
  ],
  "parameters":
  [
    {
      "name": "pretrained-model",
      "type": "model",
      "default": "retinanet_x101_32x4d_fpn_1x_coco_20200130-5c8b7ec4",
      "help": "The pretrained model to use."
    },
    {
      "name": "clear-dataset",
      "type": "bool",
      "default": "false",
      "help": "If enabled, any meta-data or predictions get removed from the dataset beforehand."
    },
    {
      "name": "min-score",
      "type": "float",
      "default": "0.0",
      "help": "The minimum score (0-1) that the predictions need to achieve for being included."
    },
    {
      "name": "mask-threshold",
      "type": "float",
      "default": "0.1",
      "help": "The threshold (0-1) to use for determining the contour of a mask."
    },
    {
      "name": "store-predictions",
      "type": "bool",
      "default": "false",
      "help": "If enabled, the predictions get stored back in the dataset that they were generated for."
    },
    {
      "name": "confidence-scores",
      "type": "str",
      "default": "ufdl.joblauncher.objdet.confidence.Common",
      "help": "The semicolon-separated list of classes for calculating confidence scores, which get stored back in the meta-data of the image."
    }
  ],
  "body": "mmdet_predict --checkpoint /output/pretrained_model.pth --config /output/config.py --labels /output/labels.txt --score ${min-score} --mask_threshold ${mask-threshold} --output_width_height --prediction_in /prediction/in/ --prediction_out /prediction/out/\n---separator---\n# model settings\nmodel = dict(\n    type='RetinaNet',\n    pretrained='open-mmlab://resnext101_32x4d',\n    backbone=dict(\n        type='ResNeXt',\n        depth=101,\n        groups=32,\n        base_width=4,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=1,\n        add_extra_convs=True,\n        num_outs=5),\n    bbox_head=dict(\n        type='RetinaHead',\n        num_classes=81,\n        in_channels=256,\n        stacked_convs=4,\n        feat_channels=256,\n        octave_base_scale=4,\n        scales_per_octave=3,\n        anchor_ratios=[0.5, 1.0, 2.0],\n        anchor_strides=[8, 16, 32, 64, 128],\n        target_means=[.0, .0, .0, .0],\n        target_stds=[1.0, 1.0, 1.0, 1.0],\n        loss_cls=dict(\n            type='FocalLoss',\n            use_sigmoid=True,\n            gamma=2.0,\n            alpha=0.25,\n            loss_weight=1.0),\n        loss_bbox=dict(type='SmoothL1Loss', beta=0.11, loss_weight=1.0)))\n# training and testing settings\ntrain_cfg = dict(\n    assigner=dict(\n        type='MaxIoUAssigner',\n        pos_iou_thr=0.5,\n        neg_iou_thr=0.4,\n        min_pos_iou=0,\n        ignore_iof_thr=-1),\n    allowed_border=-1,\n    pos_weight=-1,\n    debug=False)\ntest_cfg = dict(\n    nms_pre=1000,\n    min_bbox_size=0,\n    score_thr=0.05,\n    nms=dict(type='nms', iou_thr=0.5),\n    max_per_img=100)\n# dataset settings\ndataset_type = 'CocoDataset'\ndata_root = '/data'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(type='Resize', img_scale=(${image-width}, ${image-height}), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(${image-width}, ${image-height}),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    imgs_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        ann_file=data_root + '/train/annotations.json',\n        img_prefix=data_root + '/train/',\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        ann_file=data_root + '/val/annotations.json',\n        img_prefix=data_root + '/val/',\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        ann_file=data_root + '/test/annotations.json',\n        img_prefix=data_root + '/test/',\n        pipeline=test_pipeline))\nevaluation = dict(interval=1, metric='bbox')\n# optimizer\noptimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    step=[8, 11])\ncheckpoint_config = dict(interval=${checkpoint-interval})\n# yapf:disable\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        # dict(type='TensorboardLoggerHook')\n    ])\n# yapf:enable\n# runtime settings\ntotal_epochs = ${epochs}\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nwork_dir = '/output'\nload_from = '/data/pretrained_model.pth'\nresume_from = None\nworkflow = [('train', 1)]\n"
}
