{
  "name": "tensorflow_objectdetection_1_14_mask_rcnn_inception_v2_coco-train",
  "version": 1,
  "description": "Building Mask R-CNN Inception v2 models using ObjectDetection API for Tensorflow 1.14\nhttp://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz",
  "scope": "public",
  "domain": "od",
  "framework": "tensorflow|1.14",
  "licence": "Apache 2.0",
  "job_type": "train",
  "executor_class": "ufdl.joblauncher.objdet.tensorflow.ObjectDetectionTrain_TF_1_14",
  "required_packages": "git+https://github.com/waikato-ufdl/ufdl-job-launcher-plugins.git",
  "inputs":
  [
    {
      "name": "data",
      "type": "dataset",
      "options": "to-tfrecords -o data.tfrecords -p labels.pbtxt --split-names train test val --split-ratios 70 15 15",
      "help": "The dataset to use for building the model; gets split into 70% train, 15% test, 15% validation."
    }
  ],
  "parameters":
  [
    {
      "name": "num-train-steps",
      "type": "int",
      "default": "50000",
      "help": "The number of training steps to perform."
    },
    {
      "name": "min-dimension",
      "type": "int",
      "default": "800",
      "help": "The minimum dimension (width or height) for images."
    },
    {
      "name": "max-dimension",
      "type": "int",
      "default": "1365",
      "help": "The maximum dimension (width or height) for images."
    },
    {
      "name": "pretrained-model",
      "type": "model",
      "default": "mask_rcnn_inception_v2_coco_2018_01_28",
      "help": "The pretrained Mask R-CNN Inception v2 model to use."
    }
  ],
  "body": "model {\n  faster_rcnn {\n    number_of_stages: 3\n    num_classes: ${num-classes}\n    image_resizer {\n      keep_aspect_ratio_resizer {\n        min_dimension: ${min-dimension}\n        max_dimension: ${max-dimension}\n      }\n    }\n    feature_extractor {\n      type: \"faster_rcnn_inception_v2\"\n      first_stage_features_stride: 16\n    }\n    first_stage_anchor_generator {\n      grid_anchor_generator {\n        height_stride: 16\n        width_stride: 16\n        scales: 0.25\n        scales: 0.5\n        scales: 1.0\n        scales: 2.0\n        aspect_ratios: 0.5\n        aspect_ratios: 1.0\n        aspect_ratios: 2.0\n      }\n    }\n    first_stage_box_predictor_conv_hyperparams {\n      op: CONV\n      regularizer {\n        l2_regularizer {\n          weight: 0.0\n        }\n      }\n      initializer {\n        truncated_normal_initializer {\n          stddev: 0.00999999977648\n        }\n      }\n    }\n    first_stage_nms_score_threshold: 0.0\n    first_stage_nms_iou_threshold: 0.699999988079\n    first_stage_max_proposals: 100\n    first_stage_localization_loss_weight: 2.0\n    first_stage_objectness_loss_weight: 1.0\n    initial_crop_size: 14\n    maxpool_kernel_size: 2\n    maxpool_stride: 2\n    second_stage_box_predictor {\n      mask_rcnn_box_predictor {\n        fc_hyperparams {\n          op: FC\n          regularizer {\n            l2_regularizer {\n              weight: 0.0\n            }\n          }\n          initializer {\n            variance_scaling_initializer {\n              factor: 1.0\n              uniform: true\n              mode: FAN_AVG\n            }\n          }\n        }\n        use_dropout: false\n        dropout_keep_probability: 1.0\n        conv_hyperparams {\n          op: CONV\n          regularizer {\n            l2_regularizer {\n              weight: 0.0\n            }\n          }\n          initializer {\n            truncated_normal_initializer {\n              stddev: 0.00999999977648\n            }\n          }\n        }\n        predict_instance_masks: true\n        mask_prediction_conv_depth: 0\n        mask_height: 15\n        mask_width: 15\n        mask_prediction_num_conv_layers: 2\n      }\n    }\n    second_stage_post_processing {\n      batch_non_max_suppression {\n        score_threshold: 0.300000011921\n        iou_threshold: 0.600000023842\n        max_detections_per_class: 100\n        max_total_detections: 100\n      }\n      score_converter: SOFTMAX\n    }\n    second_stage_localization_loss_weight: 2.0\n    second_stage_classification_loss_weight: 1.0\n    second_stage_mask_prediction_loss_weight: 4.0\n  }\n}\ntrain_config {\n  batch_size: 1\n  data_augmentation_options {\n    random_horizontal_flip {\n    }\n  }\n  optimizer {\n    momentum_optimizer {\n      learning_rate {\n        manual_step_learning_rate {\n          initial_learning_rate: 0.000199999994948\n          schedule {\n            step: 900000\n            learning_rate: 1.99999994948e-05\n          }\n          schedule {\n            step: 1200000\n            learning_rate: 1.99999999495e-06\n          }\n        }\n      }\n      momentum_optimizer_value: 0.899999976158\n    }\n    use_moving_average: false\n  }\n  gradient_clipping_by_norm: 10.0\n  fine_tune_checkpoint: \"/models/pretrainedmodel/model.ckpt\"\n  from_detection_checkpoint: true\n  num_steps: 200000\n}\ntrain_input_reader {\n  label_map_path: \"/data//train/labels.pbtxt\"\n  load_instance_masks: true\n  tf_record_input_reader {\n    input_path: \"/data/train/data.tfrecords\"\n  }\n}\neval_config {\n  num_examples: 8000\n  max_evals: 10\n  use_moving_averages: false\n}\neval_input_reader {\n  label_map_path: \"/data/test/labels.pbtxt\"\n  shuffle: false\n  num_readers: 1\n  load_instance_masks: true\n  tf_record_input_reader {\n    input_path: \"/data/test/data.tfrecords\"\n  }\n}\n"
}
