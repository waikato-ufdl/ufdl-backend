{
  "name": "mmdet_2020-03-01_cuda10_mask_rcnn_r50_fpn_1x-train",
  "version": 1,
  "description": "Building Mask R-CNN ResNet50 FPN models using MMDetection 2020-03-01",
  "scope": "public",
  "domain": "od",
  "framework": "mmdetection|2020-03-01_cuda10",
  "licence": "Apache 2.0",
  "job_type": "train",
  "executor_class": "ufdl.joblauncher.objdet.mmdetection.ObjectDetectionTrain_MMDet_20200301",
  "required_packages": "git+https://github.com/waikato-ufdl/ufdl-job-launcher-plugins.git",
  "inputs":
  [
    {
      "name": "data",
      "type": "dataset",
      "options": "to-coco --sort-categories --category-output-file labels.txt -o annotations.json --split-names train test val --split-ratios 70 15 15",
      "help": "The dataset to use for building the model; gets split into 70% train, 15% test, 15% validation."
    }
  ],
  "parameters":
  [
    {
      "name": "epochs",
      "type": "int",
      "default": "200",
      "help": "The number of training epochs to perform."
    },
    {
      "name": "checkpoint-interval",
      "type": "int",
      "default": "50",
      "help": "The number of training epochs after which to save a checkpoint (at most the number of epochs)."
    },
    {
      "name": "image-width",
      "type": "int",
      "default": "1333",
      "help": "The width to scale the images to."
    },
    {
      "name": "image-height",
      "type": "int",
      "default": "800",
      "help": "The height to scale the images to."
    },
    {
      "name": "pretrained-model",
      "type": "model",
      "default": "mask_rcnn_r50_fpn_1x_20181010-069fa190",
      "help": "The pretrained ResNet50 model to use."
    },
    {
      "name": "shared-memory-size",
      "type": "str",
      "default": "8G",
      "help": "The shared memory size to use for launching the docker container."
    }
  ],
  "body": "# model settings\n# Original config file: https://github.com/open-mmlab/mmdetection/blob/v1.2.0/configs/mask_rcnn_r50_fpn_1x.py\nmodel = dict(\n    type='MaskRCNN',\n    pretrained='torchvision://resnet50',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_scales=[8],\n        anchor_ratios=[0.5, 1.0, 2.0],\n        anchor_strides=[4, 8, 16, 32, 64],\n        target_means=[.0, .0, .0, .0],\n        target_stds=[1.0, 1.0, 1.0, 1.0],\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n    bbox_roi_extractor=dict(\n        type='SingleRoIExtractor',\n        roi_layer=dict(type='RoIAlign', out_size=7, sample_num=2),\n        out_channels=256,\n        featmap_strides=[4, 8, 16, 32]),\n    bbox_head=dict(\n        type='SharedFCBBoxHead',\n        num_fcs=2,\n        in_channels=256,\n        fc_out_channels=1024,\n        roi_feat_size=7,\n        num_classes=81,\n        target_means=[0., 0., 0., 0.],\n        target_stds=[0.1, 0.1, 0.2, 0.2],\n        reg_class_agnostic=False,\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0)),\n    mask_roi_extractor=dict(\n        type='SingleRoIExtractor',\n        roi_layer=dict(type='RoIAlign', out_size=14, sample_num=2),\n        out_channels=256,\n        featmap_strides=[4, 8, 16, 32]),\n    mask_head=dict(\n        type='FCNMaskHead',\n        num_convs=4,\n        in_channels=256,\n        conv_out_channels=256,\n        num_classes=81,\n        loss_mask=dict(\n            type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)))\n# model training and testing settings\ntrain_cfg = dict(\n    rpn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.7,\n            neg_iou_thr=0.3,\n            min_pos_iou=0.3,\n            ignore_iof_thr=-1),\n        sampler=dict(\n            type='RandomSampler',\n            num=256,\n            pos_fraction=0.5,\n            neg_pos_ub=-1,\n            add_gt_as_proposals=False),\n        allowed_border=0,\n        pos_weight=-1,\n        debug=False),\n    rpn_proposal=dict(\n        nms_across_levels=False,\n        nms_pre=2000,\n        nms_post=2000,\n        max_num=2000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.5,\n            neg_iou_thr=0.5,\n            min_pos_iou=0.5,\n            ignore_iof_thr=-1),\n        sampler=dict(\n            type='RandomSampler',\n            num=512,\n            pos_fraction=0.25,\n            neg_pos_ub=-1,\n            add_gt_as_proposals=True),\n        mask_size=28,\n        pos_weight=-1,\n        debug=False))\ntest_cfg = dict(\n    rpn=dict(\n        nms_across_levels=False,\n        nms_pre=1000,\n        nms_post=1000,\n        max_num=1000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=dict(\n        score_thr=0.05,\n        nms=dict(type='nms', iou_thr=0.5),\n        max_per_img=100,\n        mask_thr_binary=0.5))\n# dataset settings\ndataset_type = 'CocoDataset'\ndata_root = '/data'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='Resize', img_scale=(${image-width}, ${image-height}), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(${image-width}, ${image-height}),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    imgs_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        ann_file=data_root + '/train/annotations.json',\n        img_prefix=data_root + '/train/',\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        ann_file=data_root + '/val/annotations.json',\n        img_prefix=data_root + '/val/',\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        ann_file=data_root + '/test/annotations.json',\n        img_prefix=data_root + '/test/',\n        pipeline=test_pipeline))\n# optimizer\noptimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    step=[8, 11])\ncheckpoint_config = dict(interval=${checkpoint-interval})\n# yapf:disable\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        # dict(type='TensorboardLoggerHook')\n    ])\n# yapf:enable\nevaluation = dict(interval=1)\n# runtime settings\ntotal_epochs = ${epochs}\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nwork_dir = '/output'\nload_from = '/data/pretrained_model.pth'\nresume_from = None\nworkflow = [('train', 1)]\n"
}
